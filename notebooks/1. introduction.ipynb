{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "**BE SURE TO ADD PATH TO `src/*` TO YOUR `ENVIROMENT/LIB/PYTHONVESRION/SITEPACKAGE/tnn.pth`** !\n",
    "# Introduction to Tree NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trees and DecisionUnits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tnn import DecisionUnit, Tree\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# simple model\n",
    "class Double(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return 2 * x\n",
    "\n",
    "# tree either doubles x or leaves it\n",
    "tree= Tree(1, 2, [nn.Identity(), Double()])\n",
    "\n",
    "# For educational purpuses:\n",
    "# We will set bias to 0 and weights to 0.5\n",
    "# and get an uniform distribution over paths \n",
    "with torch.no_grad():\n",
    "    tree.distribution.linear.weight.fill_(0.5)\n",
    "    tree.distribution.linear.bias.fill_(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets sample a few outputs of this simple tree for input $[1]$ and calculate $E([1])$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input = tensor([1.])\n",
      "tensor([1.])\n",
      "tensor([2.])\n",
      "tensor([1.])\n",
      "tensor([2.])\n",
      "tensor([2.])\n",
      "E(Tree(x)) = tensor([1.5000], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones((1,))\n",
    "print(f\"input = {x}\")\n",
    "for i in range(5):\n",
    "    print(tree(x, select_max=False))\n",
    "\n",
    "E = tree.expected_value(lambda z : z, x)\n",
    "print(f\"E(Tree(x)) = {E}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "Different mothods of training will be shown. We will try to model a following function:\n",
    "$$\n",
    "f(x,y) = \\begin{cases}\n",
    "xy & x > 0, y > 0 \\\\\n",
    "e^x + y & x > 0, y \\leq  0 \\\\\n",
    "2x \\leq  0, y \\leq  0 \\\\ \n",
    "y & x \\leq 0, y > 0 \\\\\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x, y):\n",
    "    if x > 0:\n",
    "        if y > 0:\n",
    "            return x * y \n",
    "        else:\n",
    "            return torch.exp(x) + y\n",
    "    else:\n",
    "        if y > 0:\n",
    "            return y \n",
    "        else:\n",
    "            return 2*x \n",
    "\n",
    "def vector_f(z):\n",
    "    return f(z[0], z[1])\n",
    "\n",
    "# get training data:\n",
    "n_points = 100\n",
    "n_data = n_points ** 2 \n",
    "points = torch.linspace(-5, 5, n_points)\n",
    "X = torch.zeros((n_data, 2))\n",
    "Z = torch.zeros((n_data, 1))\n",
    "for index_x in range(n_points):\n",
    "    for index_y in range(n_points):\n",
    "        x = points[index_x]\n",
    "        y = points[index_y]\n",
    "        X[index_y + index_x * n_points] = torch.tensor([x, y])\n",
    "        Z[index_y + index_x * n_points] = f(x, y)\n",
    "\n",
    "# get testing data:\n",
    "n_points = 31\n",
    "n_data = n_points ** 2 \n",
    "points = torch.linspace(-5, 5, n_points)\n",
    "test_X = torch.zeros((n_data, 2))\n",
    "test_Z = torch.zeros((n_data, 1))\n",
    "for index_x in range(n_points):\n",
    "    for index_y in range(n_points):\n",
    "        x = points[index_x]\n",
    "        y = points[index_y]\n",
    "        X[index_y + index_x * n_points] = torch.tensor([x, y])\n",
    "        Z[index_y + index_x * n_points] = f(x, y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shallow Tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import FeedForward\n",
    "tree = Tree(2, 2, [FeedForward(2, 3, 1), FeedForward(2, 3, 1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primitive training without additional cost function\n",
    "We can just minimalize E[L(x)]. Bad performance expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Primitive training + force softmax to converge to delta \n",
    "Mogoče se nam splača forsirat distribucijo (pred softmaxom..?) v to smer, da je na eni točki ful velika, drugje pa mala"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2-step training of Tree:\n",
    "We can alternate between training the parameters of the inside linear layers and the parameters of the outside layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punish small gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Force inner network to be perpendicular to siblings of its parents\n",
    "\n",
    "Slabo iz tega vidika, da mogoče na koncu  vseeno rabiš prevert kej, na kar smo bli pravkokotni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Štetje ničel v vektorju za vsakim hidden layerjem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.4032, -0.0350],\n",
       "         [ 0.2718, -0.0058]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.3246,  0.6160], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.4319, -0.0500]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.4209], requires_grad=True)]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = FeedForward(2, 2, 1)\n",
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.7628"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-0.4032  -0.3246   -0.0350"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([-0.7628,  0.8821], grad_fn=<ViewBackward0>),\n",
       " tensor([0.0000, 0.8821], grad_fn=<ReluBackward0>),\n",
       " tensor([0.0000, 0.9801], grad_fn=<MulBackward0>),\n",
       " tensor([-0.4699], grad_fn=<ViewBackward0>)]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.ones((2))\n",
    "model(x, training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.2748, 0.2748],\n",
       "         [0.0000, 0.0000]], grad_fn=<TBackward0>),\n",
       " tensor([0.2748, 0.0000], grad_fn=<ViewBackward0>),\n",
       " tensor([[0.0566, 0.0000]], grad_fn=<TBackward0>),\n",
       " tensor([1.]))"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "grads = torch.autograd.grad(\n",
    "outputs=model(x),\n",
    "inputs=[p for p in model.parameters() if p.requires_grad],\n",
    "create_graph=True  # allows you to compute gradients of this gradient\n",
    ")\n",
    "grads"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
