{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probs:\n",
      " tensor([[1.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 1.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 1.0000],\n",
      "        [0.3000, 0.3000, 0.4000]])\n",
      "tensor([0, 1, 2, 1]);   tensor([0, 1, 2, 2]);   tensor([0, 1, 2, 0]);   tensor([0, 1, 2, 0]);   tensor([0, 1, 2, 0]);   \n",
      "sample of dist of batch:\n",
      " tensor([0, 1, 2, 0])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0., -0.],\n",
       "        [ 1., -1.],\n",
       "        [ 2., -2.],\n",
       "        [ 0., -0.]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "from tnn import DecisionUnit\n",
    "from torch.distributions import Categorical\n",
    "\n",
    "x = torch.tensor([[1,-1],[1,-1],[1,-1],[1,-1]], dtype=torch.float)\n",
    "probs = torch.tensor([[1, 0, 0], [0, 1, 0], [0,0,1], [0.3, 0.3, 0.4]], dtype=torch.float)\n",
    "print(\"probs:\\n\", probs)\n",
    "dist = Categorical(probs)\n",
    "for i in range(5):\n",
    "    print(dist.sample(), end=\";   \")\n",
    "print()\n",
    "\n",
    "sample = dist.sample()\n",
    "print(\"sample of dist of batch:\\n\", sample)\n",
    "\n",
    "b1 = lambda x : 0*x \n",
    "b2 = lambda x : x \n",
    "b3 = lambda x : 2 * x \n",
    "branches = [b1, b2, b3]\n",
    "\n",
    "outputs = [None] * 4  # placeholder\n",
    "\n",
    "for index, branch in enumerate(branches):\n",
    "    # Find rows where samples == model_idx\n",
    "    mask = (sample == index)\n",
    "    if mask.any():\n",
    "        x_subset = x[mask]  # rows for this model\n",
    "        out_subset = branch(x_subset)  # batch\n",
    "        # Put back into outputs\n",
    "        indices = mask.nonzero(as_tuple=True)[0]\n",
    "        for j, idx in enumerate(indices):\n",
    "            outputs[idx] = out_subset[j]\n",
    "outputs = torch.stack(outputs, dim=0)\n",
    "outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from tnn import DecisionUnit\n",
    "from torch.distributions import Categorical\n",
    "\n",
    "x = torch.tensor([[1,-1],[1,-1],[1,-1],[1,-1]], dtype=torch.float)\n",
    "probs = torch.tensor([[1, 0, 0], [0, 1, 0], [0,0,1], [0.3, 0.3, 0.4]], dtype=torch.float)\n",
    "\n",
    "sample =  torch.argmax(probs, dim=1) \n",
    "print(\"sample of dist of batch:\\n\", sample)\n",
    "\n",
    "b1 = lambda x : 0*x \n",
    "b2 = lambda x : x \n",
    "b3 = lambda x : 2 * x \n",
    "branches = [b1, b2, b3]\n",
    "\n",
    "outputs = [None] * 4  # placeholder\n",
    "\n",
    "for index, branch in enumerate(branches):\n",
    "    # Find rows where samples == model_idx\n",
    "    mask = (sample == index)\n",
    "    if mask.any():\n",
    "        x_subset = x[mask]  # rows for this model\n",
    "        out_subset = branch(x_subset)  # batch\n",
    "        # Put back into outputs\n",
    "        indices = mask.nonzero(as_tuple=True)[0]\n",
    "        for j, idx in enumerate(indices):\n",
    "            outputs[idx] = out_subset[j]\n",
    "outputs = torch.stack(outputs, dim=0)\n",
    "outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch:\n",
      " tensor([[0., 0., 0.],\n",
      "        [1., 2., 3.],\n",
      "        [2., 4., 6.],\n",
      "        [3., 6., 9.]])\n",
      "probs for two different branches (brach 1 has probability 1):\n",
      " tensor([[1., 0.],\n",
      "        [2., 1.],\n",
      "        [3., 2.],\n",
      "        [4., 3.]])\n",
      "outputs of different branches\n",
      " tensor([[[ 1.],\n",
      "         [ 1.],\n",
      "         [ 1.],\n",
      "         [ 1.]],\n",
      "\n",
      "        [[-1.],\n",
      "         [-1.],\n",
      "         [-1.],\n",
      "         [-1.]]])\n",
      "branches * probs:\n",
      " tensor([[[ 1.],\n",
      "         [ 2.],\n",
      "         [ 3.],\n",
      "         [ 4.]],\n",
      "\n",
      "        [[-0.],\n",
      "         [-1.],\n",
      "         [-2.],\n",
      "         [-3.]]]) \n",
      "of shape torch.Size([2, 4, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "from tnn import DecisionUnit\n",
    "\n",
    "batch = torch.tensor([[i, 2*i, 3*i] for i in range(4)], dtype= torch.float)\n",
    "print(\"batch:\\n\", batch)\n",
    "\n",
    "d = DecisionUnit(3, 2)\n",
    "probs = d(batch)\n",
    "probs = torch.tensor([[1 + i, 0 + i] for i in range(4)], dtype= torch.float)\n",
    "print(\"probs for two different branches (brach 1 has probability 1):\\n\", probs)\n",
    "\n",
    "# batch, mapped by different branches\n",
    "# b1 sums the row\n",
    "# b2 returns 0 for each row\n",
    "b1 = lambda x : torch.zeros((x.shape[0], 1)) + 1\n",
    "b2 = lambda x : torch.zeros((x.shape[0], 1)) -1\n",
    "branches = torch.stack([b1(batch), b2(batch)])\n",
    "print(\"outputs of different branches\\n\" , branches)\n",
    "\n",
    "\n",
    "probs_t = probs.transpose(0,1)\n",
    "E = branches * probs_t.unsqueeze(2)\n",
    "\n",
    "print(\"branches * probs:\\n\", E, \"\\nof shape\", E.shape )\n",
    "\n",
    "#E = torch.reshape(E, (4, 2))\n",
    "E.sum(dim=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kako dela autograd: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 0.5200,  0.0397],\n",
       "         [ 0.4938, -0.6666]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.6722, 0.1079], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.1349,  0.3691]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.4685], requires_grad=True)]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from models import FeedForward\n",
    "\n",
    "\n",
    "model = FeedForward(2, 2, 1)\n",
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([-0.9274, -0.4060], grad_fn=<ViewBackward0>), tensor([0., 0.], grad_fn=<ReluBackward0>), tensor([0., 0.], grad_fn=<MulBackward0>), tensor([-0.0010], grad_fn=<ViewBackward0>)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(-0.9274, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.ones((2))\n",
    "print(model(x, training=True))\n",
    "\n",
    "# množimo iz desne s transposed matriko. TO je isto, kot če bi množil vrstico z vrstico\n",
    "torch.dot(list(model.parameters())[0][0], x) + list(model.parameters())[1][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets use grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0.],\n",
       "         [0., 0.]], grad_fn=<TBackward0>),\n",
       " tensor([0., 0.], grad_fn=<ViewBackward0>),\n",
       " tensor([[0., 0.]], grad_fn=<TBackward0>),\n",
       " tensor([1.]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "grads = torch.autograd.grad(\n",
    "outputs=model(x),\n",
    "inputs=[p for p in model.parameters() if p.requires_grad],\n",
    "create_graph=True  # allows you to compute gradients of this gradient\n",
    ")\n",
    "grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1.], grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = grads[0]\n",
    "torch.relu(1-torch.norm(g, dim=0))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
